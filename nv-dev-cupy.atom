<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>https://forums.developer.nvidia.com</id>
  <title>NVIDIA Developer Forums (cupy)</title>
  <updated>2022-05-03T09:57:48.428000+00:00</updated>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator>
  <entry>
    <id>https://forums.developer.nvidia.com/t/160626/1</id>
    <title>Why do two commands show my cuda version not consistent? [1]</title>
    <updated>2020-11-28T09:21:51.862000+00:00</updated>
    <content>lingvisa: ...250W | 0MiB / 16280MiB | 0% Default | +-------------------------------+----------------------+----------------------+ Then, I did this: # pip install cupy-cuda100 And test it: In [1]: import cupy ...: a = cupy.zeros((5, 5)) --------------------------------------------------------------------------- Impo...</content>
    <link href="https://forums.developer.nvidia.com/t/160626/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/161385/2</id>
    <title>Fast, Flexible Allocation for NVIDIA CUDA with RAPIDS Memory Manager [2]</title>
    <updated>2020-12-08T23:47:43.769000+00:00</updated>
    <content>Mark Harris: ...te parts about the project is the ways in which it has been adapted for use with other CUDA-accelerated libraries and applications, such as Numba and CuPy, as well as all of the RAPIDS libraries. We look forward to hearing your questions and comments on this post and on RMM! Thanks, Mark</content>
    <link href="https://forums.developer.nvidia.com/t/161385/2" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/109687/3</id>
    <title>Cupy and TensorRT [3]</title>
    <updated>2020-12-16T10:04:50.601000+00:00</updated>
    <content>Xcf1996: same question !!! did you solve it?</content>
    <link href="https://forums.developer.nvidia.com/t/109687/3" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/164365/1</id>
    <title>CuPy error when pushing / popping pycuda context [1]</title>
    <updated>2020-12-22T23:22:59.846000+00:00</updated>
    <content>: I am using Python and tensorRT to perform inference with CUDA. I’d like to use CuPy to preprocess some images that I’ll feed to the tensorRT engine. The preprocessing function, called my_function , works fine as long as tensorRT is n...</content>
    <link href="https://forums.developer.nvidia.com/t/164365/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/166704/1</id>
    <title>Speeding up frame conversion [1]</title>
    <updated>2021-01-25T08:09:04.058000+00:00</updated>
    <content>Armita450: ...cessing of each frame, the instruction which takes the more time, about 50%, is the conversion to float32. To speedup this instruction I tried to use Cupy, a package which use GPU acceleration to do numpy instruction but cupy.float32(frame) is as long as numpy’s. The purpose of this conversion is to con...</content>
    <link href="https://forums.developer.nvidia.com/t/166704/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/169614/4</id>
    <title>Gnuradio and cuda with gr-cuda [4]</title>
    <updated>2021-03-02T10:07:49.569000+00:00</updated>
    <content>Julianmartinezsou: ...s/cuda/ init .py”, line 34, in from gpu_kernel import gpu_kernel File “/usr/local/lib/python2.7/dist-packages/cuda/gpu_kernel.py”, line 27, in import cupy as cp File “/home/juli/.local/lib/python2.7/site-packages/cupy/ init .py”, line 47, in import cupyx as _cupyx File “/home/juli/.local/lib/python2.7/s...</content>
    <link href="https://forums.developer.nvidia.com/t/169614/4" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/170894/1</id>
    <title>How to access to image array in GPU buffer without copy to CPU buffer? [1]</title>
    <updated>2021-03-14T07:34:08.715000+00:00</updated>
    <content>LoveNvidia: ...ustom inference model in that plugin. In that example for copying image array into CPU buffer is used numpy lib, I want to know is it possible to use CuPy lib or other ML framework to access to image array in GPU memory?</content>
    <link href="https://forums.developer.nvidia.com/t/170894/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/172852/1</id>
    <title>10 Minutes to Data Science: Transitioning Between RAPIDS cuDF and CuPy Libraries [1]</title>
    <updated>2021-03-19T21:01:27.526000+00:00</updated>
    <content>Jen Witsoe: Originally published at: https://developer.nvidia.com/blog/10-minutes-to-data-science-transitioning-between-rapids-cudf-and-cupy-libraries/ 10 Minutes to Data Science: Transitioning Between RAPIDS cuDF and CuPy Libraries | NVIDIA Developer Blog This post was originally publishe...</content>
    <link href="https://forums.developer.nvidia.com/t/172852/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/173024/1</id>
    <title>Free TensorRT GPU memory using Python API [1]</title>
    <updated>2021-03-22T19:02:53.759000+00:00</updated>
    <content>: ...ltiple times, I see that the GPU utilization increases of a few Mb each time, so maybe there is some kind of memory leak. I am getting measures using cupy free_bytes, total_bytes = cp.cuda.Device(0).mem_info . Here’s how I allocate my model: import pycuda.driver as cuda cuda.init() import cupy as cp imp...</content>
    <link href="https://forums.developer.nvidia.com/t/173024/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/173207/1</id>
    <title>Error: Some events were lost. How do I fix this? [1]</title>
    <updated>2021-03-24T10:51:32.574000+00:00</updated>
    <content>Jonathan Boyle: I’m profiling Python code which uses CUDA (e.g. CuPy) and always get an error about events being lost e.g. Some events (328,938) were lost. Certain charts (including CPU utilization) on the timeline may...</content>
    <link href="https://forums.developer.nvidia.com/t/173207/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/173658/1</id>
    <title>Nvidia-smi command not found despite installing CUDA [1]</title>
    <updated>2021-03-29T21:08:58.797000+00:00</updated>
    <content>David H Pitt: I installed CUDA on my Win10 machine this morning to use CuPy. Running nvcc --version gives an output, and so does conda list cudatoolkit. However, running nvidia-smi in a conda environment gives the error comma...</content>
    <link href="https://forums.developer.nvidia.com/t/173658/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/174053/1</id>
    <title>How can I create my custom containers for Jetson Nano [1]</title>
    <updated>2021-04-02T11:23:55.754000+00:00</updated>
    <content>: ...? l4t-tensorflow:r32.5.0-tf2.3-py3 TensorFlow 2.3.1 l4t-ml:r32.5.0-py3 TensorFlow 1.15 PyTorch v1.7.0 torchvision v0.8.0 torchaudio v0.7.0 onnx 1.8.0 CuPy 8.0.0 numpy 1.19.4 numba 0.52.0 OpenCV 4.4.1 pandas 1.1.5 scipy 1.5.4 scikit-learn 0.23.2 JupyterLab 2.2.9 Cheers</content>
    <link href="https://forums.developer.nvidia.com/t/174053/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/173773/2</id>
    <title>N Ways to SAXPY: Demonstrating the Breadth of GPU Programming Options [2]</title>
    <updated>2021-04-06T21:41:48.167000+00:00</updated>
    <content>dsingalNV: ...mance, allow better use of Unified Memory, etc. Furthermore, there have been more open source projects that allow one to program for NVIDIA GPUs like cuPy, Numba, Tensorflow, Pytorch and more are always showing up thanks to the https://developer.nvidia.com/cuda-llvm-compiler NVIDIA Compiler SDK Thanks f...</content>
    <link href="https://forums.developer.nvidia.com/t/173773/2" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/174959/7</id>
    <title>Unifying the CUDA Python Ecosystem [7]</title>
    <updated>2021-04-28T19:58:52.237000+00:00</updated>
    <content>Matt Nicely: ...to use the corresponding Driver/Runtime API. As far as question 2, I’m not sure at the moment. I’m pretty sure that functionality currently exists in CuPy.</content>
    <link href="https://forums.developer.nvidia.com/t/174959/7" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/169103/15</id>
    <title>Cupy crashes on Jetson Nano [15]</title>
    <updated>2021-04-29T13:58:35.876000+00:00</updated>
    <content>Alain Paillou: Hello Dustin, could this be an illustration of what you are talking about, but this time using cupy : // Copyright 2008-2021 Andreas Kloeckner // Copyright 2021 NVIDIA Corporation import pycuda.autoinit # noqa from pycuda.compiler import SourceModul...</content>
    <link href="https://forums.developer.nvidia.com/t/169103/15" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/178315/3</id>
    <title>CUDA in Python C/C++ extensions [3]</title>
    <updated>2021-05-20T15:48:12.796000+00:00</updated>
    <content>Matt Nicely: To mix CUDA/C++/Python, check out how CuPy accomplished this with NVRTC https://github.com/cupy/cupy/pull/3319 github.com/cupy/cupy Pull Request https://github.com/cupy/cupy/pull/3319 Support...</content>
    <link href="https://forums.developer.nvidia.com/t/178315/3" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/178647/2</id>
    <title>Unwrap: shift phase angles kernel implementation [2]</title>
    <updated>2021-05-24T13:09:21.586000+00:00</updated>
    <content>Matt Nicely: Have you looked at the CuPy implementation? https://github.com/cupy/cupy/blob/v9.0.0/cupy/_math/trigonometric.py#L115</content>
    <link href="https://forums.developer.nvidia.com/t/178647/2" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/179311/4</id>
    <title>Thank You NVIDIA - Everything is working fine on wsl2 and windows 10 [4]</title>
    <updated>2021-05-31T08:09:29.149000+00:00</updated>
    <content>K Glimps: ...yper, murmurhash, blis, numpy, requests, pathy, jinja2, packaging, catalogue Required-by: spacy-transformers mabd@LAPTOP-T8DQ9UK0:~$ i had to install cupy-cuda112 and here cuda 11.2 was important mabd@LAPTOP-T8DQ9UK0:~$ pip show cupy-cuda112 Name: cupy-cuda112 Version: 8.6.0 Summary: CuPy: A NumPy-compa...</content>
    <link href="https://forums.developer.nvidia.com/t/179311/4" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/179453/5</id>
    <title>Passing scalar to functions (cupy &amp;amp; pycuda) - scalar multiplication of a vector [5]</title>
    <updated>2021-05-31T21:25:41.467000+00:00</updated>
    <content>Zsolt Majzik: Thank you very very much! This is exactly what I need to study!</content>
    <link href="https://forums.developer.nvidia.com/t/179453/5" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/180564/1</id>
    <title>Gauss Rank Transformation Is 100x Faster with RAPIDS and CuPy [1]</title>
    <updated>2021-06-11T15:00:19.782000+00:00</updated>
    <content>Jen Witsoe: Originally published at: https://developer.nvidia.com/blog/gauss-rank-transformation-is-100x-faster-with-rapids-and-cupy/ Gauss Rank Transformation Is 100x Faster with RAPIDS and CuPy | NVIDIA Developer Blog As explained in the Batch Normalization paper, training neural...</content>
    <link href="https://forums.developer.nvidia.com/t/180564/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/183295/2</id>
    <title>Efficient math functions on Xavier CPU [2]</title>
    <updated>2021-07-11T17:43:49.622000+00:00</updated>
    <content>Dominik: ...chapter/libc_19.html glibc . When using Python look at https://numpy.org/doc/stable/reference/routines.math.html Numpy math functions or https://docs.cupy.dev/en/stable/reference/math.html Cupy which speeds up computation by using GPU.</content>
    <link href="https://forums.developer.nvidia.com/t/183295/2" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/186501/2</id>
    <title>Computer Vision Python packages with Cuda-GPU support for Jetson AGX Xavier? [2]</title>
    <updated>2021-08-13T14:54:50.670000+00:00</updated>
    <content>dusty_nv: Hi @Tamas23 , the other popular ones I am familiar with are cupy (numpy for CUDA), pyCUDA (run CUDA kernels from Python), numba (autovectorization for GPU). I would check out the latest https://ngc.nvidia.com/catal...</content>
    <link href="https://forums.developer.nvidia.com/t/186501/2" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/158008/8</id>
    <title>MPI Multi-GPU process list in nvidia-smi [8]</title>
    <updated>2021-09-10T15:15:32.637000+00:00</updated>
    <content>Richard Elkins: ...device. Thank you and I will inform people about this issue thread. Sample configuration: OS : Linux-4.15.0-72-generic-x86_64-with-debian-stretch-sid CuPy Version : 8.6.0 NumPy Version : 1.21.1 SciPy Version : 1.7.0 Cython Build Version : 0.29.22 CUDA Root : /opt/conda CUDA Build Version : 11000 CUDA Dr...</content>
    <link href="https://forums.developer.nvidia.com/t/158008/8" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/189099/3</id>
    <title>CuPy installation on the Nano [3]</title>
    <updated>2021-09-14T07:16:59.021000+00:00</updated>
    <content>Yuvalg1987: Hi, I tried to compile it on a fresh image of the Nano and works!</content>
    <link href="https://forums.developer.nvidia.com/t/189099/3" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/184412/9</id>
    <title>Combine pycuda and cupy [9]</title>
    <updated>2021-09-20T21:58:40.975000+00:00</updated>
    <content>system: This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</content>
    <link href="https://forums.developer.nvidia.com/t/184412/9" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/190439/1</id>
    <title>Linux kernel 5.10+ CUDA_ERROR_MISALIGNED_ADDRESS [1]</title>
    <updated>2021-09-29T17:09:28.989000+00:00</updated>
    <content>Dyckoe: ...on the cpu. Eventually everything freezes anyway. This happens much more quickly than case 1. Case 3: Trying to diagnose what is going on I insalled cupy and wrote a little python script that crunches some numbers on the gpu. import numpy as np import cupy as cp import time print('Running Test...') s =...</content>
    <link href="https://forums.developer.nvidia.com/t/190439/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/191013/1</id>
    <title>CuCIM I/O error [1]</title>
    <updated>2021-10-01T08:51:15.070000+00:00</updated>
    <content>Bilalbkr92: ...ptly shuts down while reading any image. I would like to know what needs to be done. Currently, I use CPU libraries to read images then convert it to CuPy arrays.</content>
    <link href="https://forums.developer.nvidia.com/t/191013/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/191108/4</id>
    <title>Invalid_handel [4]</title>
    <updated>2021-10-05T08:50:41.087000+00:00</updated>
    <content>Yuvalg1987: Hi, is seems that this issue is caused by the need to run CuPy and ZED in two different threads as they have different contexts.</content>
    <link href="https://forums.developer.nvidia.com/t/191108/4" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/191442/1</id>
    <title>Ubuntu20.04 + nvidia-driver-470 - card drops out after minimal use /delay after first cuda command but works w/nvidia-driver-460 [1]</title>
    <updated>2021-10-07T00:18:23.708000+00:00</updated>
    <content>Nick Cammorato: ...ning processes found | +-----------------------------------------------------------------------------+ works fine… at first. Can even dot matrixes in cupy. However after a few minutes (or hits of the driver, I can’t tell), it breaks / drops out and becomes a ‘no devices found’ that doesn’t respond to re...</content>
    <link href="https://forums.developer.nvidia.com/t/191442/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/192517/1</id>
    <title>Access gstreamer output on GPU for fast inference [1]</title>
    <updated>2021-10-20T03:26:28.261000+00:00</updated>
    <content>: ...if there is any component that I can use to replace appsink that would allow me to access the frame directly on the GPU using any cuda library (e.g. cupy , pycuda ).</content>
    <link href="https://forums.developer.nvidia.com/t/192517/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/191833/7</id>
    <title>Problem to Install TensorFlow&amp;lt;2.0 on jetson xavier [7]</title>
    <updated>2021-10-26T07:16:51.305000+00:00</updated>
    <content>AastaLLL: ...do -H pip3 install scipy==1.5 # Numba sudo apt-get install -y llvm-8 llvm-8-dev sudo -H LLVM_CONFIG=/usr/bin/llvm-config-8 pip3 install numba==0.48 # CuPy Thanks.</content>
    <link href="https://forums.developer.nvidia.com/t/191833/7" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/193826/2</id>
    <title>Using CURAND inside NVRTC (JIT-compiled) kernels [2]</title>
    <updated>2021-11-02T17:46:00.198000+00:00</updated>
    <content>Robert_Crovella: ...sume you are referring to the device API. For that, if it were me, I would use https://github.com/NVIDIA/jitify/issues/43 jitify . For example, AFAIK cupy uses this method (jitify) to enable support for curand device API in cupy user-defined kernels.</content>
    <link href="https://forums.developer.nvidia.com/t/193826/2" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/193860/1</id>
    <title>How to access cuda array on gpu in Python [1]</title>
    <updated>2021-11-02T23:45:30.835000+00:00</updated>
    <content>: ...hon 3.6 and DeepStream 5.1. I would like to decode an Rtsp video stream and to access the decoded frames on the gpu using libraries such as pycuda or cupy (other libraries might work too). I don’t want to access numpy array because I don’t want to copy the data to the cpu. It is my understanding that nv...</content>
    <link href="https://forums.developer.nvidia.com/t/193860/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/193426/5</id>
    <title>Running ROS2 Galactic and Cupy on a Docker on the Jetson Xavier NX [5]</title>
    <updated>2021-11-17T06:38:46.590000+00:00</updated>
    <content>system: This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.</content>
    <link href="https://forums.developer.nvidia.com/t/193426/5" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/196073/1</id>
    <title>How could I accelerate FFT on Nano? [1]</title>
    <updated>2021-11-24T06:10:59.633000+00:00</updated>
    <content>: ...on Nano, and I currently use the scipy.fftpack.fft()。 But the speed is so slow and I want to utilize the GPU to accelerate this process. I have tried cupy, but it takes more time than before. Does there exist any other way to do FFT on GPU in Nano? I know that pycuda could, but implement a FFT in C seem...</content>
    <link href="https://forums.developer.nvidia.com/t/196073/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/196698/1</id>
    <title>Deserialize engine failed because file path: &amp;hellip;/resnet10.caffemodel_b1_gpu0_int8.engine open error [1]</title>
    <updated>2021-11-30T23:43:57.450000+00:00</updated>
    <content>: ...orama==0.3.7 command-not-found==0.3 configobj==5.0.6 constantly==15.1.0 contextlib2==0.6.0.post1 contextvars==2.4 cronex==0.1.3.1 cryptography==2.1.4 cupy-cuda113==9.6.0 cycler==0.11.0 Cython==0.29.24 dataclasses==0.8 decorator==5.1.0 dill==0.3.4 distro-info===0.18ubuntu0.18.04.1 docutils==0.14 ec2-hibi...</content>
    <link href="https://forums.developer.nvidia.com/t/196698/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/56757/15</id>
    <title>Cuda sha256 calculations improvements [15]</title>
    <updated>2021-12-10T09:53:44.384000+00:00</updated>
    <content>Viddi Mardiansyah: Thank you very much for your quick response. I will be trying hard to figure this out. Will try with pycuda or numba or cupy.</content>
    <link href="https://forums.developer.nvidia.com/t/56757/15" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/199347/1</id>
    <title>Nearly all cuQuantum-python tests fail (installed using conda on Fedora 35) [1]</title>
    <updated>2021-12-31T22:12:20.946000+00:00</updated>
    <content>Steve Jeffrey: ...onda-forge attrs 21.2.0 pyhd3eb1b0_0 ca-certificates 2021.10.26 h06a4308_2 certifi 2021.10.8 py37h06a4308_0 cudatoolkit 11.5.0 h36ae40a_9 conda-forge cupy 10.0.0 py37hd2d9f0c_0 conda-forge cuquantum 0.1.0.30 h5c60f85_1 conda-forge cuquantum-python 0.1.0.0 py37hac9ef86_2 conda-forge cutensor 1.4.0.6 h753...</content>
    <link href="https://forums.developer.nvidia.com/t/199347/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/199790/19</id>
    <title>Cupy and loops [19]</title>
    <updated>2022-01-06T23:08:10.100000+00:00</updated>
    <content>: ...: This info, already included in the error output, could be your starting point to get more information: Thanks, I saw that, and now after installing cupy also in in the root environment using sudo works.</content>
    <link href="https://forums.developer.nvidia.com/t/199790/19" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/161486/7</id>
    <title>I compiled opencv 4.5 but did not update Python-Opencv [7]</title>
    <updated>2022-01-15T03:07:01.962000+00:00</updated>
    <content>: ...sic platform you want. JetPack 4.6 (L4T R32.6.1) l4t-ml:r32.6.1-py3 TensorFlow 1.15.5 PyTorch v1.9.0 torchvision v0.10.0 torchaudio v0.9.0 onnx 1.8.0 CuPy 9.2.0 numpy 1.19.5 numba 0.53.1 OpenCV 4.5.0 (with CUDA) pandas 1.1.5 scipy 1.5.4 scikit-learn 0.23.2 JupyterLab 2.2.9 save your time on docker, firs...</content>
    <link href="https://forums.developer.nvidia.com/t/161486/7" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/203936/3</id>
    <title>Installing cupy on jetson nano [3]</title>
    <updated>2022-03-09T17:47:34.387000+00:00</updated>
    <content>system: This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.</content>
    <link href="https://forums.developer.nvidia.com/t/203936/3" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/204695/3</id>
    <title>CuPy or other parallel methods for GPU usage on TX2? [3]</title>
    <updated>2022-03-14T19:25:06.067000+00:00</updated>
    <content>system: This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.</content>
    <link href="https://forums.developer.nvidia.com/t/204695/3" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/203654/12</id>
    <title>Cupy or pycuda on Jetson Xavier NX [12]</title>
    <updated>2022-03-23T05:21:43.480000+00:00</updated>
    <content>system: This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.</content>
    <link href="https://forums.developer.nvidia.com/t/203654/12" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/204836/6</id>
    <title>Cupy and DNN_BACKENDCUDA -&amp;gt; All Fail on TX2 [6]</title>
    <updated>2022-03-23T06:32:36.460000+00:00</updated>
    <content>system: This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.</content>
    <link href="https://forums.developer.nvidia.com/t/204836/6" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/211069/1</id>
    <title>CUDA in l4t-base:r34.1 [1]</title>
    <updated>2022-04-13T09:48:06.225000+00:00</updated>
    <content>ambrose.maker: Hello, I would like to build docker image with l4t-base:r34.1. But seems my installation process (build CuPy) cannot find CUDA, with error like this: fatal error: cuda.h: No such file or directory And the nvcc command not found nvcc --version bash: nvcc: com...</content>
    <link href="https://forums.developer.nvidia.com/t/211069/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/210913/6</id>
    <title>Cupy Install for Jetson Xavier NX [6]</title>
    <updated>2022-04-18T02:33:02.415000+00:00</updated>
    <content>AastaLLL: Hi, kmaehashi Thanks for this information. I will share this information with other users that are interested in cupy. Thanks.</content>
    <link href="https://forums.developer.nvidia.com/t/210913/6" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/211040/9</id>
    <title>PyTorch 1.11 for JetPack 5.0 DP? [9]</title>
    <updated>2022-04-25T19:05:17.965000+00:00</updated>
    <content>znmeb: ...ages on L4T-base and I want the latest stable binaries that are built by someone else whenever possible. My current Docker build only uses cusignal / cupy and torchaudio built from source, and that takes about 2.3 hours on a Xavier NX. The last time I built a PyTorch wheel I think it was 3.5 hours on th...</content>
    <link href="https://forums.developer.nvidia.com/t/211040/9" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/204142/4</id>
    <title>CUDA memory error calculating shap values although enough memory [4]</title>
    <updated>2022-04-25T23:20:29.127000+00:00</updated>
    <content>system: This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.</content>
    <link href="https://forums.developer.nvidia.com/t/204142/4" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/212739/2</id>
    <title>Nvc++ OpenACC runtime segfaults if Intel MKL (numpy) is already loaded [2]</title>
    <updated>2022-04-27T17:14:12.149000+00:00</updated>
    <content>Mat Colgrove: ...dding the flag “-nomp” when creating the shared object so NVOMP isn’t linked in. Alternately, if you can install numpy without MKL, or better yet use cupy so the Python code can be offloaded to the GPU as well. https://www.nvidia.com/en-us/glossary/data-science/numpy/ NVIDIA Data Science Glossary https:...</content>
    <link href="https://forums.developer.nvidia.com/t/212739/2" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/212436/20</id>
    <title>Nvidia Cuda Compiler not showing up in Linux 22.04 [20]</title>
    <updated>2022-05-03T09:57:48.428000+00:00</updated>
    <content>Ksimady: ...ame warning stating that the installation was incomplete and the driver version not high enough appeared. But I have still done some tests (installed cupy in a virtual environment) and it seems that the matrix operations in fact run on the GPU. So even with this message cuda can still be installed and u...</content>
    <link href="https://forums.developer.nvidia.com/t/212436/20" rel="alternate"/>
  </entry>
</feed>
