<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>https://forums.developer.nvidia.com</id>
  <title>NVIDIA Developer Forums (cupy)</title>
  <updated>2023-05-06T16:39:36.054000+00:00</updated>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator>
  <entry>
    <id>https://forums.developer.nvidia.com/t/196073/1</id>
    <title>How could I accelerate FFT on Nano? [1]</title>
    <updated>2021-11-24T06:10:59.633000+00:00</updated>
    <content>: ...on Nano, and I currently use the scipy.fftpack.fft()。 But the speed is so slow and I want to utilize the GPU to accelerate this process. I have tried cupy, but it takes more time than before. Does there exist any other way to do FFT on GPU in Nano? I know that pycuda could, but implement a FFT in C seem...</content>
    <link href="https://forums.developer.nvidia.com/t/196073/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/196698/1</id>
    <title>Deserialize engine failed because file path: &amp;hellip;/resnet10.caffemodel_b1_gpu0_int8.engine open error [1]</title>
    <updated>2021-11-30T23:43:57.450000+00:00</updated>
    <content>: ...orama==0.3.7 command-not-found==0.3 configobj==5.0.6 constantly==15.1.0 contextlib2==0.6.0.post1 contextvars==2.4 cronex==0.1.3.1 cryptography==2.1.4 cupy-cuda113==9.6.0 cycler==0.11.0 Cython==0.29.24 dataclasses==0.8 decorator==5.1.0 dill==0.3.4 distro-info===0.18ubuntu0.18.04.1 docutils==0.14 ec2-hibi...</content>
    <link href="https://forums.developer.nvidia.com/t/196698/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/56757/15</id>
    <title>Cuda sha256 calculations improvements [15]</title>
    <updated>2021-12-10T09:53:44.384000+00:00</updated>
    <content>Viddi Mardiansyah: Thank you very much for your quick response. I will be trying hard to figure this out. Will try with pycuda or numba or cupy.</content>
    <link href="https://forums.developer.nvidia.com/t/56757/15" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/198279/1</id>
    <title>CUDA hangs during cuInit [1]</title>
    <updated>2021-12-16T23:39:24.117000+00:00</updated>
    <content>: The first time a process interacts with cuda, it seems to cause a 10s-of-seconds hang. For instance, cupy.cuda.runtime.getDeviceCount() takes over 60 seconds the first time it is called, but subsequent calls within the same process are fast. A basic hello...</content>
    <link href="https://forums.developer.nvidia.com/t/198279/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/199347/1</id>
    <title>Nearly all cuQuantum-python tests fail (installed using conda on Fedora 35) [1]</title>
    <updated>2021-12-31T22:12:20.946000+00:00</updated>
    <content>Steve Jeffrey: ...onda-forge attrs 21.2.0 pyhd3eb1b0_0 ca-certificates 2021.10.26 h06a4308_2 certifi 2021.10.8 py37h06a4308_0 cudatoolkit 11.5.0 h36ae40a_9 conda-forge cupy 10.0.0 py37hd2d9f0c_0 conda-forge cuquantum 0.1.0.30 h5c60f85_1 conda-forge cuquantum-python 0.1.0.0 py37hac9ef86_2 conda-forge cutensor 1.4.0.6 h753...</content>
    <link href="https://forums.developer.nvidia.com/t/199347/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/199790/19</id>
    <title>Cupy and loops [19]</title>
    <updated>2022-01-06T23:08:10.100000+00:00</updated>
    <content>: ...: This info, already included in the error output, could be your starting point to get more information: Thanks, I saw that, and now after installing cupy also in in the root environment using sudo works.</content>
    <link href="https://forums.developer.nvidia.com/t/199790/19" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/161486/7</id>
    <title>I compiled opencv 4.5 but did not update Python-Opencv [7]</title>
    <updated>2022-01-15T03:07:01.962000+00:00</updated>
    <content>: ...sic platform you want. JetPack 4.6 (L4T R32.6.1) l4t-ml:r32.6.1-py3 TensorFlow 1.15.5 PyTorch v1.9.0 torchvision v0.10.0 torchaudio v0.9.0 onnx 1.8.0 CuPy 9.2.0 numpy 1.19.5 numba 0.53.1 OpenCV 4.5.0 (with CUDA) pandas 1.1.5 scipy 1.5.4 scikit-learn 0.23.2 JupyterLab 2.2.9 save your time on docker, firs...</content>
    <link href="https://forums.developer.nvidia.com/t/161486/7" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/203936/3</id>
    <title>Installing cupy on jetson nano [3]</title>
    <updated>2022-03-09T17:47:34.387000+00:00</updated>
    <content>system: This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.</content>
    <link href="https://forums.developer.nvidia.com/t/203936/3" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/204695/3</id>
    <title>CuPy or other parallel methods for GPU usage on TX2? [3]</title>
    <updated>2022-03-14T19:25:06.067000+00:00</updated>
    <content>system: This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.</content>
    <link href="https://forums.developer.nvidia.com/t/204695/3" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/203654/12</id>
    <title>Cupy or pycuda on Jetson Xavier NX [12]</title>
    <updated>2022-03-23T05:21:43.480000+00:00</updated>
    <content>system: This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.</content>
    <link href="https://forums.developer.nvidia.com/t/203654/12" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/204836/6</id>
    <title>Cupy and DNN_BACKENDCUDA -&amp;gt; All Fail on TX2 [6]</title>
    <updated>2022-03-23T06:32:36.460000+00:00</updated>
    <content>system: This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.</content>
    <link href="https://forums.developer.nvidia.com/t/204836/6" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/211069/1</id>
    <title>CUDA in l4t-base:r34.1 [1]</title>
    <updated>2022-04-13T09:48:06.225000+00:00</updated>
    <content>ambrose.maker: Hello, I would like to build docker image with l4t-base:r34.1. But seems my installation process (build CuPy) cannot find CUDA, with error like this: fatal error: cuda.h: No such file or directory And the nvcc command not found nvcc --version bash: nvcc: com...</content>
    <link href="https://forums.developer.nvidia.com/t/211069/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/211040/9</id>
    <title>PyTorch 1.11 for JetPack 5.0 DP? [9]</title>
    <updated>2022-04-25T19:05:17.965000+00:00</updated>
    <content>znmeb: ...ages on L4T-base and I want the latest stable binaries that are built by someone else whenever possible. My current Docker build only uses cusignal / cupy and torchaudio built from source, and that takes about 2.3 hours on a Xavier NX. The last time I built a PyTorch wheel I think it was 3.5 hours on th...</content>
    <link href="https://forums.developer.nvidia.com/t/211040/9" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/204142/4</id>
    <title>CUDA memory error calculating shap values although enough memory [4]</title>
    <updated>2022-04-25T23:20:29.127000+00:00</updated>
    <content>system: This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.</content>
    <link href="https://forums.developer.nvidia.com/t/204142/4" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/212739/2</id>
    <title>Nvc++ OpenACC runtime segfaults if Intel MKL (numpy) is already loaded [2]</title>
    <updated>2022-04-27T17:14:12.149000+00:00</updated>
    <content>Mat Colgrove: ...dding the flag “-nomp” when creating the shared object so NVOMP isn’t linked in. Alternately, if you can install numpy without MKL, or better yet use cupy so the Python code can be offloaded to the GPU as well. https://www.nvidia.com/en-us/glossary/data-science/numpy/ NVIDIA Data Science Glossary https:...</content>
    <link href="https://forums.developer.nvidia.com/t/212739/2" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/212436/21</id>
    <title>Nvidia Cuda Compiler not showing up in Linux 22.04 [21]</title>
    <updated>2022-05-03T10:25:07.377000+00:00</updated>
    <content>Johnnynuca14: ...nk the next update of cuda and drivers will be quite big. I am on kernel 5.17.5 and it is completely stable with these drivers using cudnn, tensorrt, cupy and cudf for deep learning.</content>
    <link href="https://forums.developer.nvidia.com/t/212436/21" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/210913/8</id>
    <title>Cupy Install for Jetson Xavier NX [8]</title>
    <updated>2022-05-11T03:46:52.479000+00:00</updated>
    <content>system: This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.</content>
    <link href="https://forums.developer.nvidia.com/t/210913/8" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/215440/1</id>
    <title>Low performance on Drive AGX Driver [1]</title>
    <updated>2022-05-24T14:24:41.578000+00:00</updated>
    <content>Muhammed Al Kadi: ...us DevKit (E3550) other SDK Manager Version 1.8.0.10363 other Host Machine Version native Ubuntu 18.04 other I managed recently to install our Python/CuPy based Radar signal processing framework on Drive AGX Xavier dev kit. After doing some comparisons to other GPUs, I’m surprised that Drive AGX is sign...</content>
    <link href="https://forums.developer.nvidia.com/t/215440/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/213644/2</id>
    <title>Processing camera samples from RTSP to Redis with ffmpeg [2]</title>
    <updated>2022-05-25T10:23:46.847000+00:00</updated>
    <content>dsingalNV: ...idth copying frames to the GPU, decoding, and then sending them out to be read via numpy. Numpy: Since numpy uses system memory, using something like cupy that can access the data on GPU memory itself would reduce the memory copy from GPU memory to system memory. For future reference, our technical blog...</content>
    <link href="https://forums.developer.nvidia.com/t/213644/2" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/215554/1</id>
    <title>Using NVSHMEM on a Python Library [1]</title>
    <updated>2022-05-25T10:37:29.415000+00:00</updated>
    <content>guilhermehartmannk8bwe: I currently provide a CUDA library for a client in a similar model as cupy. I was wondering if it is possible to launch this code over nvshmem and how would be the best method do it. Ideally I would like to wrap the nvshmem...</content>
    <link href="https://forums.developer.nvidia.com/t/215554/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/216751/2</id>
    <title>CUDA Python vs PyCUDA [2]</title>
    <updated>2022-06-07T15:40:39.532000+00:00</updated>
    <content>Robert_Crovella: .../unifying-the-cuda-python-ecosystem/ blog and the questions that follow it may be of interest. FWIW there are other python/CUDA methodologies. numba, cupy, CUDA python, and pycuda are some of the available approaches to tap into CUDA acceleration from Python. CUDA Python can interoperate with most or al...</content>
    <link href="https://forums.developer.nvidia.com/t/216751/2" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/216041/8</id>
    <title>[TensorRT] ERROR: 1: [resize.cu::performLinearKernelLaunch::457] Error Code 1: Cuda Runtime (invalid argument) [8]</title>
    <updated>2022-06-14T18:04:36.114000+00:00</updated>
    <content>system: This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.</content>
    <link href="https://forums.developer.nvidia.com/t/216041/8" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/219698/1</id>
    <title>Gpu-cpu memory copying is slower in WSL?! [1]</title>
    <updated>2022-07-04T14:13:59.257000+00:00</updated>
    <content>K Glimps: ...le bit slower roughly in the range some milliseconds slower. Also Python stuff caching and memory copying less than Windows. I tested Pycuda-PyopenCL-Cupy-Numba. for big arrays. these python stuff i don’t know they double cache or what. Now, I write my kernels and run them from Pycuda. Writing them in C...</content>
    <link href="https://forums.developer.nvidia.com/t/219698/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/217721/4</id>
    <title>Windows 11 WSL2 CUDA (Windows 11 Home 22000.708, Nvidia Studio Driver 512.96) [4]</title>
    <updated>2022-07-05T08:48:31.840000+00:00</updated>
    <content>K Glimps: ...6_64/21.3/cuda/11.2/bin:$PATH For any CUDA stuff fist you have to define path to your CUDA installation That is normal. For, Numba, Pycuda, Pyopencl, cupy and I think the same for tensorflow</content>
    <link href="https://forums.developer.nvidia.com/t/217721/4" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/219869/1</id>
    <title>How many kernels you can launch in WSL wiith respect to Windows [1]</title>
    <updated>2022-07-06T06:12:16.873000+00:00</updated>
    <content>K Glimps: ...uch since then. BIG mistake of WRI. So, I played with python stuff in order “to couple” with sage and cython. Numba has a limited CUDA functionality. CUPY is more oriented. They are nice within their field of application = makes life easier. Pycuda and Pyopencl were different for me, having a Ryzen 7, I...</content>
    <link href="https://forums.developer.nvidia.com/t/219869/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/221501/1</id>
    <title>cuQuantum on Jetson Xavier AGX development kit [1]</title>
    <updated>2022-07-21T20:08:13.954000+00:00</updated>
    <content>Arthur Lobo: ..., line 52, in A_d = cp.random.random((np.prod(extentA),), dtype=np.float32) File “/home/arthurlobo/.conda/envs/qml_py310/lib/python3.10/site-packages/cupy/random/_sample.py”, line 156, in random_sample return rs.random_sample(size=size, dtype=dtype) File “/home/arthurlobo/.conda/envs/qml_py310/lib/pytho...</content>
    <link href="https://forums.developer.nvidia.com/t/221501/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/220998/21</id>
    <title>When WSL is faster than Windows?! [21]</title>
    <updated>2022-07-24T14:54:03.055000+00:00</updated>
    <content>K Glimps: ...ially, I have chosen Ubuntu 18.04 because it is widely used but now, python 3.6 is old and I can not update to new/future releases of numpy &amp;gt; 1.20 or cupy &amp;gt; 9.6. That is bad. I shall install another WSL more recent and see the difference anyway one side of the equation w11 is always constant. W11 numpy:...</content>
    <link href="https://forums.developer.nvidia.com/t/220998/21" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/221843/5</id>
    <title>Shared memory parallel processing for jetson inference [5]</title>
    <updated>2022-07-26T15:03:13.522000+00:00</updated>
    <content>dusty_nv: ...CUDA stream or with cudaDeviceSynchronize() that synchronization occurs. If you are using numpy for your operations today, you may want to look into cupy, which is like the CUDA version of numpy.</content>
    <link href="https://forums.developer.nvidia.com/t/221843/5" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/226656/8</id>
    <title>SingleAsianOption Performance vs Tensorflow/Cupy [8]</title>
    <updated>2022-08-31T18:26:18.272000+00:00</updated>
    <content>Robert_Crovella: ...careful benchmarking exercise (IMO) should do a warm-up run before computing measured values. Yes, I guess you are probably not doing this with your cupy code. But I can definitely spot some problems in the comparison. So I’m fairly convinced what you’re doing is not an apples-to-apples comparison. Her...</content>
    <link href="https://forums.developer.nvidia.com/t/226656/8" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/230153/4</id>
    <title>Nsight Systems causes CuPy to crash in Windows 10 if nvcc is invoked for kernel compilation [4]</title>
    <updated>2022-10-19T18:33:54.653000+00:00</updated>
    <content>hwilper: @dofek for Windows target.</content>
    <link href="https://forums.developer.nvidia.com/t/230153/4" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/72048/1205</id>
    <title>PyTorch for Jetson [1205]</title>
    <updated>2022-10-25T19:17:29.143000+00:00</updated>
    <content>Gaversano: ...# According to the catalog, this includes: # * # * TensorFlow 1.15 # * PyTorch v1.6.0 # * torchvision v0.7.0 # * torchaudio v0.6.0 # * onnx 1.7.0 # * CuPy 8.0.0 # * numpy 1.19.2 # * numba 0.51.2 # * pandas 1.1.3 # * scipy 1.5.3 # * scikit-learn 0.23.2 # * JupyterLab 2.2.8 # # It targets NVIDIA's JetPack...</content>
    <link href="https://forums.developer.nvidia.com/t/72048/1205" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/233167/2</id>
    <title>CuDNN is not enabled [2]</title>
    <updated>2022-11-08T16:10:43.969000+00:00</updated>
    <content>Kenichi Maehashi: fujimoto7: CuDNN 8201 cupy 7.8.0 PyTorch 1.8.0 chainer 7.8.1 I’d suggest avoid using Chainer as it is no longer actively maintained to support recent platforms including Arm. H...</content>
    <link href="https://forums.developer.nvidia.com/t/233167/2" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/234580/2</id>
    <title>NVIDIA CUDA cannot work properly [2]</title>
    <updated>2022-11-17T03:46:16.669000+00:00</updated>
    <content>Tjk9501: The error prompted when using cupy looks like follows: Traceback (most recent call last): File "C:\Users\hp\.conda\envs\CUPY\lib\site-packages\spyder_kernels\py3compat.py", line 356, i...</content>
    <link href="https://forums.developer.nvidia.com/t/234580/2" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/234582/1</id>
    <title>NVIDIA CUDA cannot work properly [1]</title>
    <updated>2022-11-17T03:53:30.190000+00:00</updated>
    <content>Tjk9501: ...ew, torch.isfinite(tensor_view) &amp;amp; tensor_view.ne(0)) RuntimeError: CUDA error: an illegal memory access was encountered After some times, I installed cupy packages and run some linear algebra calculations on the same server, it seems that python can smoothly run some caluclations, but the same error wil...</content>
    <link href="https://forums.developer.nvidia.com/t/234582/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/234491/9</id>
    <title>VPI library with Jetsons? [9]</title>
    <updated>2022-11-19T16:37:31.236000+00:00</updated>
    <content>Alain Paillou: Hello Honey_Patouceul, well, i tried import pycuda.autoprimaryctx and … it seems it works ! No error message any more when i use Pycuda and Cupy toghether ! Tada ! I will test this with Pycuda and VPI to see if this solve the issue. If it is true that Pycuda can work with Cupy and VPI, this wi...</content>
    <link href="https://forums.developer.nvidia.com/t/234491/9" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/239826/1</id>
    <title>FP64 computation on budget [1]</title>
    <updated>2023-01-17T10:03:20.883000+00:00</updated>
    <content>Bingmadelaire: ...: Basically, we have a matrix A that is 70,000,000 x 15,000 (~10 TB) and want to calculate transpose(A)*A. I did some simple tests in Python with the cupy library and a 10,000,000x15,000 FP32 matrix and found the GPU to be multiple times faster. I know it will depend on the CPU and GPU, but let’s just w...</content>
    <link href="https://forums.developer.nvidia.com/t/239826/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/241232/1</id>
    <title>MONAI framework is very slow while computing stain normalisation [1]</title>
    <updated>2023-02-01T05:27:54.443000+00:00</updated>
    <content>Vinay: ...I framework. I have checked the blog for the implementation of Stain normalization and I found out that the implementation is using numpy rather than cupy or something similar. Here is the implementation, I found from MONAI blog : Copyright (c) MONAI Consortium Licensed under the Apache License, Version...</content>
    <link href="https://forums.developer.nvidia.com/t/241232/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/175800/3</id>
    <title>cuCIM: Rapid n-Dimensional Image Processing and I/O on GPUs [3]</title>
    <updated>2023-02-01T19:43:23.813000+00:00</updated>
    <content>gigony: ...://anaconda.org/rapidsai/cucim/files Files :: Anaconda.org (arm64 SBSA includes Jetson boards such as Jetson Xavior/Orin). If you are able to install CuPy package ( https://github.com/cupy/cupy/issues/3196#issuecomment-975623298 Add arm64 binary for Jetson Nano · Issue #3196 · cupy/cupy · GitHub and htt...</content>
    <link href="https://forums.developer.nvidia.com/t/175800/3" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/242195/2</id>
    <title>Getting DFP to generate monthly based models [2]</title>
    <updated>2023-02-09T15:37:55.551000+00:00</updated>
    <content>Pmackinnon: ...dia/label/cuda-11.5.2 cuda-python 11.7.0 py38h3fd9d12_0 nvidia cudatoolkit 11.5.1 hcf5317a_9 nvidia cudf 22.10.00 cuda_11_py38_g8ffe375d85_0 rapidsai cupy 9.5.0 py38h7818112_1 conda-forge curl 7.87.0 h6312ad2_0 conda-forge cycler 0.11.0 pypi_0 pypi cyrus-sasl 2.1.27 h957375c_6 conda-forge cython 0.29.24...</content>
    <link href="https://forums.developer.nvidia.com/t/242195/2" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/240655/23</id>
    <title>Cupy installation on Nvidia Drive AGX Xavier [23]</title>
    <updated>2023-02-15T15:55:03.282000+00:00</updated>
    <content>gibin.zachariah: thank you for the confirmation. We will upgrade to 5.2.6 and try .</content>
    <link href="https://forums.developer.nvidia.com/t/240655/23" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/244423/1</id>
    <title>Known Issue in CuPy affecting Tensor Interop [1]</title>
    <updated>2023-02-28T20:12:32.684000+00:00</updated>
    <content>Jin: If you are passing CuPy coordinates from a native Python operator to Holoviz, if you run into the error [2023-02-28 00:34:25.313] [holoscan] [error] [gxf_wrapper.cpp:68] Exc...</content>
    <link href="https://forums.developer.nvidia.com/t/244423/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/245196/1</id>
    <title>Cuspatial demo running error [1]</title>
    <updated>2023-03-07T09:34:19.813000+00:00</updated>
    <content>Nithin M1: ...ata[k] = column.as_column( File “/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/column/column.py”, line 1887, in as_column arbitrary = cupy.ascontiguousarray(arbitrary) File “/opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_creation/from_data.py”, line 107, in ascontiguousarray r...</content>
    <link href="https://forums.developer.nvidia.com/t/245196/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/247703/1</id>
    <title>Alternative solutions for dataframe.rolling().apply(function) because its axis=1 is not supported yet! [1]</title>
    <updated>2023-03-28T00:54:27.821000+00:00</updated>
    <content>Jcgtanaka: ...all in GPU. Could you help me, please? This is the whole code: The following code block impor the necessary libraries: import cudf import cuml import cupy import yfinance as yf import numpy as np import pandas as pd import numpy as np import matplotlib.pyplot as plt import shap %matplotlib inline plt.st...</content>
    <link href="https://forums.developer.nvidia.com/t/247703/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/248888/2</id>
    <title>Accessing real and imaginary part in cupy complex ndarray under a rawkernel function [2]</title>
    <updated>2023-04-07T08:21:34.988000+00:00</updated>
    <content>Simbecker: Has anyone ever tryed to access iamg and real part of complex in rawkernel?</content>
    <link href="https://forums.developer.nvidia.com/t/248888/2" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/249858/1</id>
    <title>CUDA Multi GPU memory management [1]</title>
    <updated>2023-04-13T21:42:03.442000+00:00</updated>
    <content>Vitorjmendonca: Hello, I have got a server PC with three GPUs, RTX A6000. I’m using the three GPUs simultaneously with CuPy. The CUDA version I’ve is 12.1. I can use the three GPUs at the same time. The problem I’m having is that when I open nvidia-smi to check the GPU’s m...</content>
    <link href="https://forums.developer.nvidia.com/t/249858/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/244647/9</id>
    <title>Nsys is not collecting kernel data [9]</title>
    <updated>2023-04-14T20:23:01.054000+00:00</updated>
    <content>Mathewsdg: ...ot contain GPU memory data. Generated: &amp;lt; path &amp;gt; /report9.nsys-rep &amp;lt; path &amp;gt; /report9.sqlite The code I am testing is just a simple Python script using Cupy version 12.0.0 shown below. import cupy as cp import cupyx as cpx add_kernel = cp.RawKernel(r''' extern "C" __global__ void my_add(const float* x1, c...</content>
    <link href="https://forums.developer.nvidia.com/t/244647/9" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/251421/3</id>
    <title>Kernel time discrepancy between nsys profile and cudaEventElapsedTime [3]</title>
    <updated>2023-04-27T21:10:59.406000+00:00</updated>
    <content>Nish511: Thanks. Would you mind providing a reference example API of using CUPI in cuda code?</content>
    <link href="https://forums.developer.nvidia.com/t/251421/3" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/251625/1</id>
    <title>Deepstream6.2 python frame extraction for custom deeplearning model (TensorRT) [1]</title>
    <updated>2023-04-28T02:10:13.830000+00:00</updated>
    <content>Youngbo Song: Description Hello, i’m developing deeplearning rtsp python server, modifing deepstream_python_apps/ deepstream-imagedata-multistream-cupy. My scheme is to extract frames from pipeline through probe on deepstream-imagedata-multistream-cupy.py and apply my custom deeplearning module for c...</content>
    <link href="https://forums.developer.nvidia.com/t/251625/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/252156/2</id>
    <title>What the difference using L2 by cudaMemcpy() and from kernel? [2]</title>
    <updated>2023-05-04T10:51:44.833000+00:00</updated>
    <content>Markus Holtmanns: Hi there @qlyu and welcome to the NVIDIA developer forums! The way cudaMemcpy() behaves in terms of cache usage might be proprietary to our driver and not something to disclose. But you might want to ask the same in the forum category where you found the original post, CUDA programming, there you...</content>
    <link href="https://forums.developer.nvidia.com/t/252156/2" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/76861/707</id>
    <title>Electronically Assisted Astronomy with a Jetson Nano [707]</title>
    <updated>2023-05-06T16:39:36.054000+00:00</updated>
    <content>Alain Paillou: ...nd JetsonSky (V30_01RC and V40_03RC). Both work fine. The frame rate is a bit low but it is quite good (from 4 to 10 fps, depending of the settings). Cupy, Pytorch and opencv with Cuda are ok. If someone could test JetsonSky with a Orin Nano or a Orin NX, i would be interested with the results. Alain</content>
    <link href="https://forums.developer.nvidia.com/t/76861/707" rel="alternate"/>
  </entry>
</feed>
