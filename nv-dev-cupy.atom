<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>https://forums.developer.nvidia.com</id>
  <title>NVIDIA Developer Forums (cupy)</title>
  <updated>2022-11-20T16:48:28.528000+00:00</updated>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator>
  <entry>
    <id>https://forums.developer.nvidia.com/t/180564/1</id>
    <title>Gauss Rank Transformation Is 100x Faster with RAPIDS and CuPy [1]</title>
    <updated>2021-06-11T15:00:19.782000+00:00</updated>
    <content>Jen Witsoe: Originally published at: https://developer.nvidia.com/blog/gauss-rank-transformation-is-100x-faster-with-rapids-and-cupy/ Gauss Rank Transformation Is 100x Faster with RAPIDS and CuPy | NVIDIA Developer Blog As explained in the Batch Normalization paper, training neural...</content>
    <link href="https://forums.developer.nvidia.com/t/180564/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/183295/2</id>
    <title>Efficient math functions on Xavier CPU [2]</title>
    <updated>2021-07-11T17:43:49.622000+00:00</updated>
    <content>Dominik: ...chapter/libc_19.html glibc . When using Python look at https://numpy.org/doc/stable/reference/routines.math.html Numpy math functions or https://docs.cupy.dev/en/stable/reference/math.html Cupy which speeds up computation by using GPU.</content>
    <link href="https://forums.developer.nvidia.com/t/183295/2" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/186501/2</id>
    <title>Computer Vision Python packages with Cuda-GPU support for Jetson AGX Xavier? [2]</title>
    <updated>2021-08-13T14:54:50.670000+00:00</updated>
    <content>dusty_nv: Hi @Tamas23 , the other popular ones I am familiar with are cupy (numpy for CUDA), pyCUDA (run CUDA kernels from Python), numba (autovectorization for GPU). I would check out the latest https://ngc.nvidia.com/catal...</content>
    <link href="https://forums.developer.nvidia.com/t/186501/2" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/158008/8</id>
    <title>MPI Multi-GPU process list in nvidia-smi [8]</title>
    <updated>2021-09-10T15:15:32.637000+00:00</updated>
    <content>Richard Elkins: ...device. Thank you and I will inform people about this issue thread. Sample configuration: OS : Linux-4.15.0-72-generic-x86_64-with-debian-stretch-sid CuPy Version : 8.6.0 NumPy Version : 1.21.1 SciPy Version : 1.7.0 Cython Build Version : 0.29.22 CUDA Root : /opt/conda CUDA Build Version : 11000 CUDA Dr...</content>
    <link href="https://forums.developer.nvidia.com/t/158008/8" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/189099/3</id>
    <title>CuPy installation on the Nano [3]</title>
    <updated>2021-09-14T07:16:59.021000+00:00</updated>
    <content>Yuvalg1987: Hi, I tried to compile it on a fresh image of the Nano and works!</content>
    <link href="https://forums.developer.nvidia.com/t/189099/3" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/184412/9</id>
    <title>Combine pycuda and cupy [9]</title>
    <updated>2021-09-20T21:58:40.975000+00:00</updated>
    <content>system: This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</content>
    <link href="https://forums.developer.nvidia.com/t/184412/9" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/190439/1</id>
    <title>Linux kernel 5.10+ CUDA_ERROR_MISALIGNED_ADDRESS [1]</title>
    <updated>2021-09-29T17:09:28.989000+00:00</updated>
    <content>Dyckoe: ...on the cpu. Eventually everything freezes anyway. This happens much more quickly than case 1. Case 3: Trying to diagnose what is going on I insalled cupy and wrote a little python script that crunches some numbers on the gpu. import numpy as np import cupy as cp import time print('Running Test...') s =...</content>
    <link href="https://forums.developer.nvidia.com/t/190439/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/191013/1</id>
    <title>CuCIM I/O error [1]</title>
    <updated>2021-10-01T08:51:15.070000+00:00</updated>
    <content>Bilalbkr92: ...ptly shuts down while reading any image. I would like to know what needs to be done. Currently, I use CPU libraries to read images then convert it to CuPy arrays.</content>
    <link href="https://forums.developer.nvidia.com/t/191013/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/191108/4</id>
    <title>Invalid_handel [4]</title>
    <updated>2021-10-05T08:50:41.087000+00:00</updated>
    <content>Yuvalg1987: Hi, is seems that this issue is caused by the need to run CuPy and ZED in two different threads as they have different contexts.</content>
    <link href="https://forums.developer.nvidia.com/t/191108/4" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/191442/1</id>
    <title>Ubuntu20.04 + nvidia-driver-470 - card drops out after minimal use /delay after first cuda command but works w/nvidia-driver-460 [1]</title>
    <updated>2021-10-07T00:18:23.708000+00:00</updated>
    <content>Nick Cammorato: ...ning processes found | +-----------------------------------------------------------------------------+ works fine… at first. Can even dot matrixes in cupy. However after a few minutes (or hits of the driver, I can’t tell), it breaks / drops out and becomes a ‘no devices found’ that doesn’t respond to re...</content>
    <link href="https://forums.developer.nvidia.com/t/191442/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/192517/1</id>
    <title>Access gstreamer output on GPU for fast inference [1]</title>
    <updated>2021-10-20T03:26:28.261000+00:00</updated>
    <content>: ...if there is any component that I can use to replace appsink that would allow me to access the frame directly on the GPU using any cuda library (e.g. cupy , pycuda ).</content>
    <link href="https://forums.developer.nvidia.com/t/192517/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/191833/7</id>
    <title>Problem to Install TensorFlow&amp;lt;2.0 on jetson xavier [7]</title>
    <updated>2021-10-26T07:16:51.305000+00:00</updated>
    <content>AastaLLL: ...do -H pip3 install scipy==1.5 # Numba sudo apt-get install -y llvm-8 llvm-8-dev sudo -H LLVM_CONFIG=/usr/bin/llvm-config-8 pip3 install numba==0.48 # CuPy Thanks.</content>
    <link href="https://forums.developer.nvidia.com/t/191833/7" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/193826/2</id>
    <title>Using CURAND inside NVRTC (JIT-compiled) kernels [2]</title>
    <updated>2021-11-02T17:46:00.198000+00:00</updated>
    <content>Robert_Crovella: ...sume you are referring to the device API. For that, if it were me, I would use https://github.com/NVIDIA/jitify/issues/43 jitify . For example, AFAIK cupy uses this method (jitify) to enable support for curand device API in cupy user-defined kernels.</content>
    <link href="https://forums.developer.nvidia.com/t/193826/2" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/193860/1</id>
    <title>How to access cuda array on gpu in Python [1]</title>
    <updated>2021-11-02T23:45:30.835000+00:00</updated>
    <content>: ...hon 3.6 and DeepStream 5.1. I would like to decode an Rtsp video stream and to access the decoded frames on the gpu using libraries such as pycuda or cupy (other libraries might work too). I don’t want to access numpy array because I don’t want to copy the data to the cpu. It is my understanding that nv...</content>
    <link href="https://forums.developer.nvidia.com/t/193860/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/193426/5</id>
    <title>Running ROS2 Galactic and Cupy on a Docker on the Jetson Xavier NX [5]</title>
    <updated>2021-11-17T06:38:46.590000+00:00</updated>
    <content>system: This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.</content>
    <link href="https://forums.developer.nvidia.com/t/193426/5" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/196073/1</id>
    <title>How could I accelerate FFT on Nano? [1]</title>
    <updated>2021-11-24T06:10:59.633000+00:00</updated>
    <content>: ...on Nano, and I currently use the scipy.fftpack.fft()。 But the speed is so slow and I want to utilize the GPU to accelerate this process. I have tried cupy, but it takes more time than before. Does there exist any other way to do FFT on GPU in Nano? I know that pycuda could, but implement a FFT in C seem...</content>
    <link href="https://forums.developer.nvidia.com/t/196073/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/196698/1</id>
    <title>Deserialize engine failed because file path: &amp;hellip;/resnet10.caffemodel_b1_gpu0_int8.engine open error [1]</title>
    <updated>2021-11-30T23:43:57.450000+00:00</updated>
    <content>: ...orama==0.3.7 command-not-found==0.3 configobj==5.0.6 constantly==15.1.0 contextlib2==0.6.0.post1 contextvars==2.4 cronex==0.1.3.1 cryptography==2.1.4 cupy-cuda113==9.6.0 cycler==0.11.0 Cython==0.29.24 dataclasses==0.8 decorator==5.1.0 dill==0.3.4 distro-info===0.18ubuntu0.18.04.1 docutils==0.14 ec2-hibi...</content>
    <link href="https://forums.developer.nvidia.com/t/196698/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/56757/15</id>
    <title>Cuda sha256 calculations improvements [15]</title>
    <updated>2021-12-10T09:53:44.384000+00:00</updated>
    <content>Viddi Mardiansyah: Thank you very much for your quick response. I will be trying hard to figure this out. Will try with pycuda or numba or cupy.</content>
    <link href="https://forums.developer.nvidia.com/t/56757/15" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/199347/1</id>
    <title>Nearly all cuQuantum-python tests fail (installed using conda on Fedora 35) [1]</title>
    <updated>2021-12-31T22:12:20.946000+00:00</updated>
    <content>Steve Jeffrey: ...onda-forge attrs 21.2.0 pyhd3eb1b0_0 ca-certificates 2021.10.26 h06a4308_2 certifi 2021.10.8 py37h06a4308_0 cudatoolkit 11.5.0 h36ae40a_9 conda-forge cupy 10.0.0 py37hd2d9f0c_0 conda-forge cuquantum 0.1.0.30 h5c60f85_1 conda-forge cuquantum-python 0.1.0.0 py37hac9ef86_2 conda-forge cutensor 1.4.0.6 h753...</content>
    <link href="https://forums.developer.nvidia.com/t/199347/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/199790/19</id>
    <title>Cupy and loops [19]</title>
    <updated>2022-01-06T23:08:10.100000+00:00</updated>
    <content>: ...: This info, already included in the error output, could be your starting point to get more information: Thanks, I saw that, and now after installing cupy also in in the root environment using sudo works.</content>
    <link href="https://forums.developer.nvidia.com/t/199790/19" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/161486/7</id>
    <title>I compiled opencv 4.5 but did not update Python-Opencv [7]</title>
    <updated>2022-01-15T03:07:01.962000+00:00</updated>
    <content>: ...sic platform you want. JetPack 4.6 (L4T R32.6.1) l4t-ml:r32.6.1-py3 TensorFlow 1.15.5 PyTorch v1.9.0 torchvision v0.10.0 torchaudio v0.9.0 onnx 1.8.0 CuPy 9.2.0 numpy 1.19.5 numba 0.53.1 OpenCV 4.5.0 (with CUDA) pandas 1.1.5 scipy 1.5.4 scikit-learn 0.23.2 JupyterLab 2.2.9 save your time on docker, firs...</content>
    <link href="https://forums.developer.nvidia.com/t/161486/7" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/203936/3</id>
    <title>Installing cupy on jetson nano [3]</title>
    <updated>2022-03-09T17:47:34.387000+00:00</updated>
    <content>system: This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.</content>
    <link href="https://forums.developer.nvidia.com/t/203936/3" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/204695/3</id>
    <title>CuPy or other parallel methods for GPU usage on TX2? [3]</title>
    <updated>2022-03-14T19:25:06.067000+00:00</updated>
    <content>system: This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.</content>
    <link href="https://forums.developer.nvidia.com/t/204695/3" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/203654/12</id>
    <title>Cupy or pycuda on Jetson Xavier NX [12]</title>
    <updated>2022-03-23T05:21:43.480000+00:00</updated>
    <content>system: This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.</content>
    <link href="https://forums.developer.nvidia.com/t/203654/12" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/204836/6</id>
    <title>Cupy and DNN_BACKENDCUDA -&amp;gt; All Fail on TX2 [6]</title>
    <updated>2022-03-23T06:32:36.460000+00:00</updated>
    <content>system: This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.</content>
    <link href="https://forums.developer.nvidia.com/t/204836/6" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/211069/1</id>
    <title>CUDA in l4t-base:r34.1 [1]</title>
    <updated>2022-04-13T09:48:06.225000+00:00</updated>
    <content>ambrose.maker: Hello, I would like to build docker image with l4t-base:r34.1. But seems my installation process (build CuPy) cannot find CUDA, with error like this: fatal error: cuda.h: No such file or directory And the nvcc command not found nvcc --version bash: nvcc: com...</content>
    <link href="https://forums.developer.nvidia.com/t/211069/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/211040/9</id>
    <title>PyTorch 1.11 for JetPack 5.0 DP? [9]</title>
    <updated>2022-04-25T19:05:17.965000+00:00</updated>
    <content>znmeb: ...ages on L4T-base and I want the latest stable binaries that are built by someone else whenever possible. My current Docker build only uses cusignal / cupy and torchaudio built from source, and that takes about 2.3 hours on a Xavier NX. The last time I built a PyTorch wheel I think it was 3.5 hours on th...</content>
    <link href="https://forums.developer.nvidia.com/t/211040/9" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/204142/4</id>
    <title>CUDA memory error calculating shap values although enough memory [4]</title>
    <updated>2022-04-25T23:20:29.127000+00:00</updated>
    <content>system: This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.</content>
    <link href="https://forums.developer.nvidia.com/t/204142/4" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/212739/2</id>
    <title>Nvc++ OpenACC runtime segfaults if Intel MKL (numpy) is already loaded [2]</title>
    <updated>2022-04-27T17:14:12.149000+00:00</updated>
    <content>Mat Colgrove: ...dding the flag “-nomp” when creating the shared object so NVOMP isn’t linked in. Alternately, if you can install numpy without MKL, or better yet use cupy so the Python code can be offloaded to the GPU as well. https://www.nvidia.com/en-us/glossary/data-science/numpy/ NVIDIA Data Science Glossary https:...</content>
    <link href="https://forums.developer.nvidia.com/t/212739/2" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/212436/21</id>
    <title>Nvidia Cuda Compiler not showing up in Linux 22.04 [21]</title>
    <updated>2022-05-03T10:25:07.377000+00:00</updated>
    <content>Johnnynuca14: ...nk the next update of cuda and drivers will be quite big. I am on kernel 5.17.5 and it is completely stable with these drivers using cudnn, tensorrt, cupy and cudf for deep learning.</content>
    <link href="https://forums.developer.nvidia.com/t/212436/21" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/210913/8</id>
    <title>Cupy Install for Jetson Xavier NX [8]</title>
    <updated>2022-05-11T03:46:52.479000+00:00</updated>
    <content>system: This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.</content>
    <link href="https://forums.developer.nvidia.com/t/210913/8" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/215440/1</id>
    <title>Low performance on Drive AGX Driver [1]</title>
    <updated>2022-05-24T14:24:41.578000+00:00</updated>
    <content>Muhammed Al Kadi: ...us DevKit (E3550) other SDK Manager Version 1.8.0.10363 other Host Machine Version native Ubuntu 18.04 other I managed recently to install our Python/CuPy based Radar signal processing framework on Drive AGX Xavier dev kit. After doing some comparisons to other GPUs, I’m surprised that Drive AGX is sign...</content>
    <link href="https://forums.developer.nvidia.com/t/215440/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/213644/2</id>
    <title>Processing camera samples from RTSP to Redis with ffmpeg [2]</title>
    <updated>2022-05-25T10:23:46.847000+00:00</updated>
    <content>dsingalNV: ...idth copying frames to the GPU, decoding, and then sending them out to be read via numpy. Numpy: Since numpy uses system memory, using something like cupy that can access the data on GPU memory itself would reduce the memory copy from GPU memory to system memory. For future reference, our technical blog...</content>
    <link href="https://forums.developer.nvidia.com/t/213644/2" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/215554/1</id>
    <title>Using NVSHMEM on a Python Library [1]</title>
    <updated>2022-05-25T10:37:29.415000+00:00</updated>
    <content>guilhermehartmannk8bwe: I currently provide a CUDA library for a client in a similar model as cupy. I was wondering if it is possible to launch this code over nvshmem and how would be the best method do it. Ideally I would like to wrap the nvshmem...</content>
    <link href="https://forums.developer.nvidia.com/t/215554/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/216751/2</id>
    <title>CUDA Python vs PyCUDA [2]</title>
    <updated>2022-06-07T15:40:39.532000+00:00</updated>
    <content>Robert_Crovella: .../unifying-the-cuda-python-ecosystem/ blog and the questions that follow it may be of interest. FWIW there are other python/CUDA methodologies. numba, cupy, CUDA python, and pycuda are some of the available approaches to tap into CUDA acceleration from Python. CUDA Python can interoperate with most or al...</content>
    <link href="https://forums.developer.nvidia.com/t/216751/2" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/216041/8</id>
    <title>[TensorRT] ERROR: 1: [resize.cu::performLinearKernelLaunch::457] Error Code 1: Cuda Runtime (invalid argument) [8]</title>
    <updated>2022-06-14T18:04:36.114000+00:00</updated>
    <content>system: This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.</content>
    <link href="https://forums.developer.nvidia.com/t/216041/8" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/219698/1</id>
    <title>Gpu-cpu memory copying is slower in WSL?! [1]</title>
    <updated>2022-07-04T14:13:59.257000+00:00</updated>
    <content>K Glimps: ...le bit slower roughly in the range some milliseconds slower. Also Python stuff caching and memory copying less than Windows. I tested Pycuda-PyopenCL-Cupy-Numba. for big arrays. these python stuff i don’t know they double cache or what. Now, I write my kernels and run them from Pycuda. Writing them in C...</content>
    <link href="https://forums.developer.nvidia.com/t/219698/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/217721/4</id>
    <title>Windows 11 WSL2 CUDA (Windows 11 Home 22000.708, Nvidia Studio Driver 512.96) [4]</title>
    <updated>2022-07-05T08:48:31.840000+00:00</updated>
    <content>K Glimps: ...6_64/21.3/cuda/11.2/bin:$PATH For any CUDA stuff fist you have to define path to your CUDA installation That is normal. For, Numba, Pycuda, Pyopencl, cupy and I think the same for tensorflow</content>
    <link href="https://forums.developer.nvidia.com/t/217721/4" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/219869/1</id>
    <title>How many kernels you can launch in WSL wiith respect to Windows [1]</title>
    <updated>2022-07-06T06:12:16.873000+00:00</updated>
    <content>K Glimps: ...uch since then. BIG mistake of WRI. So, I played with python stuff in order “to couple” with sage and cython. Numba has a limited CUDA functionality. CUPY is more oriented. They are nice within their field of application = makes life easier. Pycuda and Pyopencl were different for me, having a Ryzen 7, I...</content>
    <link href="https://forums.developer.nvidia.com/t/219869/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/221501/1</id>
    <title>cuQuantum on Jetson Xavier AGX development kit [1]</title>
    <updated>2022-07-21T20:08:13.954000+00:00</updated>
    <content>Arthur Lobo: ..., line 52, in A_d = cp.random.random((np.prod(extentA),), dtype=np.float32) File “/home/arthurlobo/.conda/envs/qml_py310/lib/python3.10/site-packages/cupy/random/_sample.py”, line 156, in random_sample return rs.random_sample(size=size, dtype=dtype) File “/home/arthurlobo/.conda/envs/qml_py310/lib/pytho...</content>
    <link href="https://forums.developer.nvidia.com/t/221501/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/220998/21</id>
    <title>When WSL is faster than Windows?! [21]</title>
    <updated>2022-07-24T14:54:03.055000+00:00</updated>
    <content>K Glimps: ...ially, I have chosen Ubuntu 18.04 because it is widely used but now, python 3.6 is old and I can not update to new/future releases of numpy &amp;gt; 1.20 or cupy &amp;gt; 9.6. That is bad. I shall install another WSL more recent and see the difference anyway one side of the equation w11 is always constant. W11 numpy:...</content>
    <link href="https://forums.developer.nvidia.com/t/220998/21" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/221843/5</id>
    <title>Shared memory parallel processing for jetson inference [5]</title>
    <updated>2022-07-26T15:03:13.522000+00:00</updated>
    <content>dusty_nv: ...CUDA stream or with cudaDeviceSynchronize() that synchronization occurs. If you are using numpy for your operations today, you may want to look into cupy, which is like the CUDA version of numpy.</content>
    <link href="https://forums.developer.nvidia.com/t/221843/5" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/226656/8</id>
    <title>SingleAsianOption Performance vs Tensorflow/Cupy [8]</title>
    <updated>2022-08-31T18:26:18.272000+00:00</updated>
    <content>Robert_Crovella: ...careful benchmarking exercise (IMO) should do a warm-up run before computing measured values. Yes, I guess you are probably not doing this with your cupy code. But I can definitely spot some problems in the comparison. So I’m fairly convinced what you’re doing is not an apples-to-apples comparison. Her...</content>
    <link href="https://forums.developer.nvidia.com/t/226656/8" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/230153/4</id>
    <title>Nsight Systems causes CuPy to crash in Windows 10 if nvcc is invoked for kernel compilation [4]</title>
    <updated>2022-10-19T18:33:54.653000+00:00</updated>
    <content>hwilper: @dofek for Windows target.</content>
    <link href="https://forums.developer.nvidia.com/t/230153/4" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/72048/1205</id>
    <title>PyTorch for Jetson [1205]</title>
    <updated>2022-10-25T19:17:29.143000+00:00</updated>
    <content>Gaversano: ...# According to the catalog, this includes: # * # * TensorFlow 1.15 # * PyTorch v1.6.0 # * torchvision v0.7.0 # * torchaudio v0.6.0 # * onnx 1.7.0 # * CuPy 8.0.0 # * numpy 1.19.2 # * numba 0.51.2 # * pandas 1.1.3 # * scipy 1.5.3 # * scikit-learn 0.23.2 # * JupyterLab 2.2.8 # # It targets NVIDIA's JetPack...</content>
    <link href="https://forums.developer.nvidia.com/t/72048/1205" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/233167/2</id>
    <title>CuDNN is not enabled [2]</title>
    <updated>2022-11-08T16:10:43.969000+00:00</updated>
    <content>Kenichi Maehashi: fujimoto7: CuDNN 8201 cupy 7.8.0 PyTorch 1.8.0 chainer 7.8.1 I’d suggest avoid using Chainer as it is no longer actively maintained to support recent platforms including Arm. H...</content>
    <link href="https://forums.developer.nvidia.com/t/233167/2" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/234580/2</id>
    <title>NVIDIA CUDA cannot work properly [2]</title>
    <updated>2022-11-17T03:46:16.669000+00:00</updated>
    <content>Tjk9501: The error prompted when using cupy looks like follows: Traceback (most recent call last): File "C:\Users\hp\.conda\envs\CUPY\lib\site-packages\spyder_kernels\py3compat.py", line 356, i...</content>
    <link href="https://forums.developer.nvidia.com/t/234580/2" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/234582/1</id>
    <title>NVIDIA CUDA cannot work properly [1]</title>
    <updated>2022-11-17T03:53:30.190000+00:00</updated>
    <content>Tjk9501: ...ew, torch.isfinite(tensor_view) &amp;amp; tensor_view.ne(0)) RuntimeError: CUDA error: an illegal memory access was encountered After some times, I installed cupy packages and run some linear algebra calculations on the same server, it seems that python can smoothly run some caluclations, but the same error wil...</content>
    <link href="https://forums.developer.nvidia.com/t/234582/1" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/234491/9</id>
    <title>VPI library with Jetsons? [9]</title>
    <updated>2022-11-19T16:37:31.236000+00:00</updated>
    <content>Alain Paillou: Hello Honey_Patouceul, well, i tried import pycuda.autoprimaryctx and … it seems it works ! No error message any more when i use Pycuda and Cupy toghether ! Tada ! I will test this with Pycuda and VPI to see if this solve the issue. If it is true that Pycuda can work with Cupy and VPI, this wi...</content>
    <link href="https://forums.developer.nvidia.com/t/234491/9" rel="alternate"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/76861/592</id>
    <title>Electronically Assisted Astronomy with a Jetson Nano [592]</title>
    <updated>2022-11-20T16:48:28.528000+00:00</updated>
    <content>Alain Paillou: Hello Kenichi, many thanks for this information. In fact, i used this link to install cupy on my windows laptop but i did not noticed there was an aarch64 precompiled libreary !!! You make great job with cupy. Really great. Many thanks. Con...</content>
    <link href="https://forums.developer.nvidia.com/t/76861/592" rel="alternate"/>
  </entry>
</feed>
