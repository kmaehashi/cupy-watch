<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>https://forums.developer.nvidia.com</id>
  <title>NVIDIA Developer Forums (cupy)</title>
  <updated>2025-01-03T09:00:23.747000+00:00</updated>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <entry>
    <id>https://forums.developer.nvidia.com/t/280858/8</id>
    <title>VPI __cuda_array_interface__ Interoperability [8]</title>
    <updated>2024-02-27T06:25:54.540000+00:00</updated>
    <content>AastaLLL: There is no update from you for a period, assuming this is not an issue any more. Hence we are closing this topic. If need further support, please open a new one. Thanks Hi, Thanks for the update. Would you mind sharing the change you made with us? So we can check with our internal team to see if...</content>
    <link href="https://forums.developer.nvidia.com/t/280858/8"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/286063/5</id>
    <title>CPU utilization using deepstream on Jetson AGX [5]</title>
    <updated>2024-03-18T10:27:37.639000+00:00</updated>
    <content>Yuweiw: You may refer to our demo to use cupy https://github.com/NVIDIA-AI-IOT/deepstream_python_apps/blob/master/apps/deepstream-imagedata-multistream-cupy/deepstream_imagedata-multistream_cupy....</content>
    <link href="https://forums.developer.nvidia.com/t/286063/5"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/286806/1</id>
    <title>Illegal memory access when adding parameters in PyOptiX [1]</title>
    <updated>2024-03-20T17:04:37.849000+00:00</updated>
    <content>Alstom259: ...() File "triangle.py", line 448, in main pix = launch( pipeline, sbt, gas_handle ) File "triangle.py", line 424, in launch stream.synchronize() File "cupy/cuda/stream.pyx", line 252, in cupy.cuda.stream._BaseStream.synchronize File "cupy_backends/cuda/api/runtime.pyx", line 851, in cupy_backends.cuda.ap...</content>
    <link href="https://forums.developer.nvidia.com/t/286806/1"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/287272/1</id>
    <title>Order within triton inference server python backend [1]</title>
    <updated>2024-03-25T12:34:43.996000+00:00</updated>
    <content>Ajithkumar Ak95: ...ERWISE) ARISING IN ANY WAY OUT OF THE USE # OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. import numpy as np import cv2 import cupy as cp import time # triton_python_backend_utils is available in every Triton Python model. You # need to use this module to create inference requests...</content>
    <link href="https://forums.developer.nvidia.com/t/287272/1"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/288869/3</id>
    <title>Need Assistance in Optimizing CUDA Execution for Siamrpn tracker code [3]</title>
    <updated>2024-04-09T06:03:03.259000+00:00</updated>
    <content>AastaLLL: Hi, Could you share more about how you modify the code to GPU implementation? Do you use CuPy or other GPU-based libraries? Thanks.</content>
    <link href="https://forums.developer.nvidia.com/t/288869/3"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/290076/1</id>
    <title>Is CuPy Available? [1]</title>
    <updated>2024-04-18T07:29:00.636000+00:00</updated>
    <content>Atsushi Sakurai: ...rol the movement of objects through the Python API, currently using Numpy for vector operations. I wanted to speed up the calculations by introducing CuPy, but I received an error message saying CuPy could not be found. Is it not possible to perform calculations on the GPU when controlling forces? I am...</content>
    <link href="https://forums.developer.nvidia.com/t/290076/1"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/290711/2</id>
    <title>Executing CUDA Kernel in python [2]</title>
    <updated>2024-04-24T14:23:49.511000+00:00</updated>
    <content>Robert_Crovella: ...ludes both ctypes approach and pycuda approach, as both will use kernels written in CUDA C++) which can't currently be done in numba CUDA jit method. cupy is a bit of a different animal. I wouldn't attempt to do performance comparisons between cupy and CUDA C++. The purpose of cupy is to provide a best...</content>
    <link href="https://forums.developer.nvidia.com/t/290711/2"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/291803/1</id>
    <title>Dask is another big winner for WSL [1]</title>
    <updated>2024-05-04T09:53:47.977000+00:00</updated>
    <content>K Glimps: ...ubly-periodic, not to mention spin top and other 3 and higher dimensionals applications like in solitons. Now, i am spending my spare time with Dask, cupy, numba, cuDF. Thank you for all your hardd work and keep going on. We always need to hear your point of view and your prespective for better future o...</content>
    <link href="https://forums.developer.nvidia.com/t/291803/1"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/292704/1</id>
    <title>After ds6.2 -&amp;gt; 6.4 update, pyds import causes tensorrt to Abort (core dumped) [1]</title>
    <updated>2024-05-13T11:18:31.949000+00:00</updated>
    <content>: ...obviously is not a solution - our code which manages deepstream and dispatches GPU-resident buffers from deepstream into trt (and other places, incl. cupy ops) is a python app, so we need both of those bindings. Note - attached dockerfile builds pyds itself, but when using precompiled pyds (from https:/...</content>
    <link href="https://forums.developer.nvidia.com/t/292704/1"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/293271/5</id>
    <title>How to perform eigenvalue decompositions for large matrices with Python [5]</title>
    <updated>2024-05-17T21:29:27.745000+00:00</updated>
    <content>Sebastian Wittmeier (Curefab Technologies GmbH): ...run one of the C++/Cuda symmetric matrix examples with some modifications for your Matrix size and batch size 1 to see, whether it is a cuSolver or a CuPy limitation: https://github.com/NVIDIA/CUDALibrarySamples/tree/master/cuSOLVER github.com https://github.com/NVIDIA/CUDALibrarySamples/tree/master/cuS...</content>
    <link href="https://forums.developer.nvidia.com/t/293271/5"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/292572/3</id>
    <title>SRT H.264 video source [3]</title>
    <updated>2024-05-24T16:54:38.829000+00:00</updated>
    <content>: .... Do you know by any chance if it is possible to keep the decoded frames on the gpu using -hwaccel_output_format cuda and converting them directly to cupy array? Regarding your issue with the color space conversion, I never came across this problem.</content>
    <link href="https://forums.developer.nvidia.com/t/292572/3"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/294322/1</id>
    <title>Tensorrt python api bug when used simultaneously with pyds and gst bindings [1]</title>
    <updated>2024-05-28T09:54:16.630000+00:00</updated>
    <content>: ...obviously is not a solution - our code which manages deepstream and dispatches GPU-resident buffers from deepstream into trt (and other places, incl. cupy ops) is a python app, so we need both of those bindings. This bug reminds of an another one I posted some time ago here: https://forums.developer.nvi...</content>
    <link href="https://forums.developer.nvidia.com/t/294322/1"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/294406/9</id>
    <title>Save Frame using GPU buffer data [9]</title>
    <updated>2024-06-03T08:43:40.042000+00:00</updated>
    <content>Yuweiw: It's already a GPU buffer in the demo https://github.com/NVIDIA-AI-IOT/deepstream_python_apps/blob/master/apps/deepstream-imagedata-multistream-cupy/deepstream_imagedata-multistream_cupy.py#L115 deepstream_imagedata-multistream_cupy.py , you can use https://cupy.dev/ cupy to process the buffer as...</content>
    <link href="https://forums.developer.nvidia.com/t/294406/9"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/295072/1</id>
    <title>为什么我的 Jetson 图像处理性能不及 RTX 3060？ [1]</title>
    <updated>2024-06-04T04:14:17.953000+00:00</updated>
    <content>1930920921: 您好，本人在 Jetson AGX Orin 32GB 和 RTX 3060 运行了相同的代码，内容如下： import cupy import cv2 import cupyx.scipy.ndimage as ndi import numpy as np import time img = cv2.imread('test.jpg') img_gpu = np.asarray(img, np.float32) img_gp...</content>
    <link href="https://forums.developer.nvidia.com/t/295072/1"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/292795/4</id>
    <title>Inference on area of interest only [4]</title>
    <updated>2024-06-06T19:00:20.184000+00:00</updated>
    <content>Jin: ...d for live stream frames too. You can choose any GPU accelerated libraries you are familiar with, in the C++ API or Python API, it doesn't need to be Cupy or Numpy. Please see https://docs.nvidia.com/holoscan/sdk-user-guide/holoscan_create_operator.html This holoscan::Tensor class is a wrapper around th...</content>
    <link href="https://forums.developer.nvidia.com/t/292795/4"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/295494/1</id>
    <title>GH200 memory not clearing [1]</title>
    <updated>2024-06-06T20:29:04.896000+00:00</updated>
    <content>Ayushkoul00: I am trying to run some ML models on a GH200 GPU using CuPy, CuML and CuDF in Python. However, the memory in the GPU is almost filled. No processes are running as well. Since my program deals with a lot of mem...</content>
    <link href="https://forums.developer.nvidia.com/t/295494/1"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/295501/4</id>
    <title>Gstreamer NVMM memory buffer to torch tensor with zero copy [4]</title>
    <updated>2024-06-07T15:00:47.161000+00:00</updated>
    <content>vermillionblu: Thank you I was successfully able to cast it to torch tensor from cupy. Is it possible to do so without using pyds library bindings?</content>
    <link href="https://forums.developer.nvidia.com/t/295501/4"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/295606/1</id>
    <title>Problem using jetson tx2 with jetpack 4.6.3 with ultralytics [1]</title>
    <updated>2024-06-07T15:59:39.120000+00:00</updated>
    <content>Vlad Purhin: ...l4t-ml:r32.7.1-py3 with the following packages installed in it: TensorFlow 1.15.5 PyTorch v1.10.0 torchvision v0.11.0 torchaudio v0.10.0 onnx 1.11.0 CuPy 9.2.0 numpy 1.19.5 numba 0.53.1 OpenCV 4.5.0 (with CUDA) pandas 1.1.5 scipy 1.5.4 scikit-learn 0.24.2 JupyterLab 2.2.9 And I add CUDA settings to it...</content>
    <link href="https://forums.developer.nvidia.com/t/295606/1"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/297200/1</id>
    <title>Cudaq.sample(kernel,shots=1e7) Segmentation fault [1]</title>
    <updated>2024-06-21T01:23:22.015000+00:00</updated>
    <content>: ...hots=1024*1024 it crashes got GPU, run 1048576 shots Segmentation fault This is the software stack I'm using # pip3 list|grep cuda cuda-quantum 0.7.1 cupy-cuda12x 13.2.0 CUDA-Q Version 0.7.1 (https://github.com/NVIDIA/cuda-quantum 1f8dd79d46cad9b9bd0eb220eb04408a2e6beda4) I run on GPU is A100 # nvidia-s...</content>
    <link href="https://forums.developer.nvidia.com/t/297200/1"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/296973/2</id>
    <title>CUDARuntimeError: cudaErrorIllegalAddress: an illegal memory access was encountered [2]</title>
    <updated>2024-06-21T22:28:08.847000+00:00</updated>
    <content>Afonso Martingo C: ...this issue. I checked the new release notes and noticed that the update changed the way FormatConverterOp operates on host/device copies. I was using Cupy to acquire the frame that was sent through a Tensor Holoscan, I think the error I am facing is related to Cupy waiting for data on the GPU and after...</content>
    <link href="https://forums.developer.nvidia.com/t/296973/2"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/298222/13</id>
    <title>CUDA indexing issues [13]</title>
    <updated>2024-07-02T19:10:18.685000+00:00</updated>
    <content>Raul Valle: I edited my code above. In my new test I actually separated the tasks a bit: FWF_ACC_CPUONLY_DEBUG() is a function that generates all the intermediate outputs on the CPU sequentially. FWF_ACC_DEBUG() is a function that generates all the intermediate outputs on the GPU sequentially. In the second ...</content>
    <link href="https://forums.developer.nvidia.com/t/298222/13"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/298497/10</id>
    <title>Is the performance of cuda radix-sort related to data itself? [10]</title>
    <updated>2024-07-04T16:56:13.603000+00:00</updated>
    <content>Robert_Crovella: ...make this change, without hampering other work you are doing, then that may be another avenue to explore. Although maybe not convenient to use here, cupy sort probably knows how to do a sensible job of sorting columns of an array.</content>
    <link href="https://forums.developer.nvidia.com/t/298497/10"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/299009/4</id>
    <title>How I can parallel access the meta data for each stream? [4]</title>
    <updated>2024-07-09T05:51:22.595000+00:00</updated>
    <content>Debjit Adak: ...vds_buf_surface_gpu(hash(gst_buffer), frame_meta.batch_id) # dataptr is of type PyCapsule → Use ctypes to retrieve the pointer as an int to pass into cupy ctypes.pythonapi.PyCapsule_GetPointer.restype = ctypes.c_void_p ctypes.pythonapi.PyCapsule_GetPointer.argtypes = [ctypes.py_object, ctypes.c_char_p]...</content>
    <link href="https://forums.developer.nvidia.com/t/299009/4"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/299421/1</id>
    <title>Windows WSL / Docker Desktop users must update to Docker Desktop v4.31.1 [1]</title>
    <updated>2024-07-11T03:36:14.397000+00:00</updated>
    <content>Joe: ...PUs from the containers if they are running Docker Desktop versions older than 4.31.1 . My project was running a PyTorch image because it already had cupy in it. I found this after installing the latest NVIDIA workstation but probably isn't directly related to that. This seems like some kind of driver i...</content>
    <link href="https://forums.developer.nvidia.com/t/299421/1"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/299422/6</id>
    <title>[Resolved] Add way to recover edited file - undo changes - I corrupted requirements.txt and the container build failed [6]</title>
    <updated>2024-07-11T20:45:46.458000+00:00</updated>
    <content>Joe: Will investigate this evening. I realize that I could change the packages there remove the cupy package from Environment &amp;gt; Packages in the AI Workbench UI and rebuild the project</content>
    <link href="https://forums.developer.nvidia.com/t/299422/6"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/301509/1</id>
    <title>ImportError DLL while running PyOptiX hello.py example on Windows [1]</title>
    <updated>2024-07-29T08:33:03.049000+00:00</updated>
    <content>Alstom259: ...and followed the installation guide on Windows CMD terminal: I created a conda environment: conda create -n pyoptix-windows python numpy conda-forge::cupy pillow pytest Activated it: conda activate pyoptix-windows Installed pynvrtc: pip install pynvrtc Set the PYOPTIX_CMAKE_ARGS environment variable: se...</content>
    <link href="https://forums.developer.nvidia.com/t/301509/1"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/301656/1</id>
    <title>TensorRT 10.1: Different inference results of onnxruntime and tensorrt [1]</title>
    <updated>2024-07-30T09:15:31.928000+00:00</updated>
    <content>astan.w: ....22 CUDA Version: 12.2 Operating System + Version : Windows 10 22H2 19045.3448 Python Version: 3.10 onnxruntime version: 1.16.0 numpy version: 1.23.1 cupy version: 13.2.0 Relevant Files https://drive.google.com/file/d/1toMublS6TQgP3NZDWc8gnwJJ8qLMz9VY/view drive.google.com https://drive.google.com/file/...</content>
    <link href="https://forums.developer.nvidia.com/t/301656/1"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/303075/3</id>
    <title>Jetson with Docker [3]</title>
    <updated>2024-08-12T07:14:45.652000+00:00</updated>
    <content>AastaLLL: ...1-py3 for JetPack 5.1.1 contains: TensorFlow 2.11.0 PyTorch v2.0.0 torchvision v0.15.1 torchaudio v2.0.1 onnx 1.13.1 onnxruntime 1.16.0 optimum 1.8.8 CuPy 13.0.0 numpy 1.23.5 numba 0.56.4 PyCUDA 2022.2 OpenCV 4.5.0 (with CUDA) pandas 2.0.1 scipy 1.10.0 scikit-learn 1.2.2 diffusers 0.17.1 transformers 4....</content>
    <link href="https://forums.developer.nvidia.com/t/303075/3"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/295814/6</id>
    <title>When upgrade from CUDA12.4 to 12.5 the compilation became broken [6]</title>
    <updated>2024-08-19T06:40:42.813000+00:00</updated>
    <content>Harald Siegmund: ...r this bug and that I agree to the [Code of Conduct](CODE_OF_CONDUCT.md) ### Type of Bug Compile-time Error ### Component Thrust ### Describe the bug CuPy cannot be built due to this compiler error, which does not exist at all. I think this might be due to a missing compiler guard that used to exist som...</content>
    <link href="https://forums.developer.nvidia.com/t/295814/6"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/306145/2</id>
    <title>Is there an efficient way to implement a function similar to np.add.at() function in NumPy? [2]</title>
    <updated>2024-09-09T04:39:25.395000+00:00</updated>
    <content>njuffa: ...don't have first-hand experience in this direction, but is seems the first place where you would want to look for this functionality is in PyCUDA and CuPy. If you cannot find anything relevant there, maybe look at Thrust. yanghang162: due to the randomness of the indices, memory access efficiency is ver...</content>
    <link href="https://forums.developer.nvidia.com/t/306145/2"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/308933/1</id>
    <title>String similarity package in cudF for fuzzy merge [1]</title>
    <updated>2024-10-07T00:05:49.731000+00:00</updated>
    <content>Teslim Kuteyi: ...m = df1[key1].apply(lambda x: process.extract(x, s, scorer=fuzz.partial_ratio, limit=limit)) df1['matches'] = m I then tried this: import cudf import cupy as cp from cudf.utils.string_similarity import levenshtein_distance ( and also cudf.levenshtein_distance) def gpu_fuzzy_merge(df1, df2, key1, key2, t...</content>
    <link href="https://forums.developer.nvidia.com/t/308933/1"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/309039/1</id>
    <title>Jetson/Python: Gpu mapped buffer from gstreamer [1]</title>
    <updated>2024-10-07T18:46:22.993000+00:00</updated>
    <content>Stein: ..., I have a couple of challenges: I want to keep the buffer in NV12 format, and I want to to map the frame to the GPU for further use with CUDA ( with cupy ). I've looked the at the bindings from https://github.com/NVIDIA-AI-IOT/deepstream_python_apps/ deepstream_python_apps and see the following: https:...</content>
    <link href="https://forums.developer.nvidia.com/t/309039/1"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/309603/6</id>
    <title>Problems(and solutions) installing HPC 12.6 over Kali [6]</title>
    <updated>2024-10-14T11:45:49.183000+00:00</updated>
    <content>K Glimps: Now I can test JAX vs cupy so far jitted JAX is faster than cupy but i need to do more tests.</content>
    <link href="https://forums.developer.nvidia.com/t/309603/6"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/310677/2</id>
    <title>Cupy support [2]</title>
    <updated>2024-10-22T00:25:54.999000+00:00</updated>
    <content>Richard: This is amazing. What a great code. I will pass it along to the devs. Thanks !!</content>
    <link href="https://forums.developer.nvidia.com/t/310677/2"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/311015/1</id>
    <title>DS-7 In ARM , The saved images are all black [1]</title>
    <updated>2024-10-24T13:31:01.345000+00:00</updated>
    <content>745206234: ...ownedMemory(c_data_ptr, size, owner) # Create MemoryPointer object from unownedmem, at index 0 memptr = cp.cuda.MemoryPointer(unownedmem, 0) # Create cupy array to access the image data. This array is in GPU buffer n_frame_gpu = cp.ndarray(shape=shape, dtype=data_type, memptr=memptr, strides=strides, or...</content>
    <link href="https://forums.developer.nvidia.com/t/311015/1"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/309286/2</id>
    <title>Multiprocessing support in Isaac Sim [2]</title>
    <updated>2024-11-02T10:31:31.908000+00:00</updated>
    <content>S Dempsey: Did you pip install multiprocessing? Tbh I'm not familiar with it I just used dask and it worked. Not sure of your application I tried cupy but didn't get very far. Not sure if your aware but you need to install modules in the Isaac folder if you check the docs. Hope this helps it's not m...</content>
    <link href="https://forums.developer.nvidia.com/t/309286/2"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/312462/1</id>
    <title>Looking for a cuda distributed array library for c++ [1]</title>
    <updated>2024-11-06T19:48:27.401000+00:00</updated>
    <content>Nelsonihc: Greetings! I found an implementation in CuPy that fits my needs, but I haven't been able to find a similar library for C++. Does anyone know of a C++ library with comparable functionality? The d...</content>
    <link href="https://forums.developer.nvidia.com/t/312462/1"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/281670/2</id>
    <title>Problem with running the program from cupy [2]</title>
    <updated>2024-11-16T09:44:21.909000+00:00</updated>
    <content>Svkmongolec: if you find out why you got that error, please let me know becuase I have the same one</content>
    <link href="https://forums.developer.nvidia.com/t/281670/2"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/313531/1</id>
    <title>Catastrophic error: cannot open source file &amp;ldquo;cupy/complex.cuh&amp;rdquo; [1]</title>
    <updated>2024-11-16T09:56:20.109000+00:00</updated>
    <content>Svkmongolec: Upon installing cuda and cupy + running a basic python script import cupy as cp x = cp.array([1, 2, 3]) print(x**2) I get the following error : $ python CUDA_RESET.py Traceback (m...</content>
    <link href="https://forums.developer.nvidia.com/t/313531/1"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/313757/1</id>
    <title>Fusing Epilog Operations with Matrix Multiplication Using nvmath-python [1]</title>
    <updated>2024-11-18T18:30:27.632000+00:00</updated>
    <content>Jen Witsoe: ...l bindings to the underlying libraries and higher-level Pythonic abstractions. It is interoperable with existing Python packages, such as PyTorch and CuPy. In this post, I show how to use epilogs…</content>
    <link href="https://forums.developer.nvidia.com/t/313757/1"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/314200/23</id>
    <title>GPU Context Switching Issue in DeepStream with CuPy Post-Processing [23]</title>
    <updated>2024-12-05T09:05:45.329000+00:00</updated>
    <content>Fechen: https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#interprocess-communication CUDA C++ Programming Guide</content>
    <link href="https://forums.developer.nvidia.com/t/314200/23"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/316095/1</id>
    <title>Why is the amount of thread blocks per cluster and the dynamic shared memory that I can allocate much lower than expected? [1]</title>
    <updated>2024-12-08T17:39:12.882000+00:00</updated>
    <content>mrakgr: Link: https://github.com/cupy/cupy/issues/8778 The __cluster_dims__ annotation doesn't work as expected with CuPy. · Issue #8778 · cupy/cupy I originally thought this issue was re...</content>
    <link href="https://forums.developer.nvidia.com/t/316095/1"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/219702/24</id>
    <title>Belive or Not: SuperCuda is 10^6(+) faster than Mathematica [24]</title>
    <updated>2024-12-11T14:11:53.715000+00:00</updated>
    <content>K Glimps: ...values (100 000,100 000) Here the GPU code (the CPU is just Client) ############################################ ```python import numpy as np import cupy as cp import dask.array as da import dask from dask_cuda import LocalCUDACluster from dask.distributed import Client cluster = LocalCUDACluster() cli...</content>
    <link href="https://forums.developer.nvidia.com/t/219702/24"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/316679/7</id>
    <title>Missing Gstreamer Properties for NvUriSrcBin [7]</title>
    <updated>2024-12-16T17:03:04.271000+00:00</updated>
    <content>Dsonmez: ...ything necessary to run this demo on the Jetson side as well, I don't think there are any critical restrictions. I already have handled "DeepStream - CuPy memory pointer limitation" which could affect the Jetson integration. yuweiw: The nvurisrcbin does not include either of these 2 properties. Could yo...</content>
    <link href="https://forums.developer.nvidia.com/t/316679/7"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/315455/6</id>
    <title>&amp;ldquo;How to connect/Combine Two Jetson AGX Orin Devices to Share GPU Workload?&amp;rdquo; [6]</title>
    <updated>2024-12-18T05:17:25.444000+00:00</updated>
    <content>Whitesscott: ...Jetson AGX Orin 192.168.1.11 slots=1 # IP of Jetson Orin Nano on both Orins install: sudo apt-get install -y libopenmpi-dev openmpi-bin pip3 install cupy-cuda12x mpi4py Set up passwordless SSH between the devices. Try the test to have mpirun can run using both gpus. mpirun -np 2 -hostfile hosts python3...</content>
    <link href="https://forums.developer.nvidia.com/t/315455/6"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/317294/1</id>
    <title>Rapidsai JupyterLab cupy CUDARuntimeError: cudaErrorNoDevice: no CUDA-capable device is detected [1]</title>
    <updated>2024-12-18T09:37:04.296000+00:00</updated>
    <content>Elena Hamidy: ...on GPU (see nvidi-smi output below), however per nvtop I rarely hit the mark of 50%. Then I try to execute this code from cudf demo notebooks: import cupy as cp import pandas as pd import cudf import dask_cudf cp.random.seed(12) After this, I get this error from cupy: File /opt/conda/lib/python3.10/site...</content>
    <link href="https://forums.developer.nvidia.com/t/317294/1"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/238230/7</id>
    <title>Can&amp;rsquo;t install pycuda [7]</title>
    <updated>2024-12-24T14:11:56.065000+00:00</updated>
    <content>Alain Paillou: Maybe you could try CUPY instead of PYCUDA. https://cupy.dev/ CuPy https://cupy.dev/ CuPy NumPy &amp;amp; SciPy for GPU I used Pycuda some time ago but installation was always compli...</content>
    <link href="https://forums.developer.nvidia.com/t/238230/7"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/308077/19</id>
    <title>Running deepstream_imagedata-multistream_cupy on Jetson Orin – Alternatives to x86 Code [19]</title>
    <updated>2024-12-30T10:01:10.515000+00:00</updated>
    <content>Yingliu: There is no update from you for a period, assuming this is not an issue anymore. Hence we are closing this topic. If need further support, please open a new one. Thanks</content>
    <link href="https://forums.developer.nvidia.com/t/308077/19"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/76861/904</id>
    <title>Electronically Assisted Astronomy with a Jetson Nano [904]</title>
    <updated>2025-01-01T13:23:59.810000+00:00</updated>
    <content>Alain Paillou: ...hannel) : # HDR Test program # Alain PAILLOU - 2025 # Create HDR image from single frame generating 4 frames from this single frame import cv2 import cupy as cp def HDR_compute(image_16b,method,threshold_16b,type_bayer) : if (16 - threshold_16b) &amp;lt; = 5 : delta_th = (16 - threshold_16b) / 3.0 else : delta...</content>
    <link href="https://forums.developer.nvidia.com/t/76861/904"/>
  </entry>
  <entry>
    <id>https://forums.developer.nvidia.com/t/318671/1</id>
    <title>Multithreading with rapids [1]</title>
    <updated>2025-01-03T09:00:23.747000+00:00</updated>
    <content>Mohith Pokala: ...hread. I also tried multiprocessing. Sadly, that didn't help . I am attaching the code for reference. Any help will be appreciated import cudf import cupy as cp from concurrent.futures import ThreadPoolExecutor import torch def parallel_gpu_operations(N): """ Args: N: Number of rows """ total_gpus = tor...</content>
    <link href="https://forums.developer.nvidia.com/t/318671/1"/>
  </entry>
</feed>
